From 6c1185edff02a38a34fb5a4e61535446111c6a5f Mon Sep 17 00:00:00 2001
From: Serge-Harnyk <xenonchikmaxxx@gmail.com>
Date: Fri, 24 Mar 2017 12:36:37 +0200
Subject: [PATCH] Add new fields to log for kafka logappender.

---
 .../appenders/kafka/appender/KafkaLogAppender.java | 39 ++++++-----
 .../appenders/kafka/appender/KafkaLogEventDao.java | 79 +++++++++++-----------
 .../appenders/kafka/appender/LogEventDao.java      | 13 ++--
 3 files changed, 69 insertions(+), 62 deletions(-)

diff --git a/server/appenders/kafka-appender/src/main/java/org/kaaproject/kaa/server/appenders/kafka/appender/KafkaLogAppender.java b/server/appenders/kafka-appender/src/main/java/org/kaaproject/kaa/server/appenders/kafka/appender/KafkaLogAppender.java
index 8c0d9cd..3de1407 100644
--- a/server/appenders/kafka-appender/src/main/java/org/kaaproject/kaa/server/appenders/kafka/appender/KafkaLogAppender.java
+++ b/server/appenders/kafka-appender/src/main/java/org/kaaproject/kaa/server/appenders/kafka/appender/KafkaLogAppender.java
@@ -16,17 +16,6 @@
 
 package org.kaaproject.kaa.server.appenders.kafka.appender;
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
-import java.util.concurrent.ScheduledExecutorService;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicInteger;
-
 import org.apache.avro.generic.GenericRecord;
 import org.apache.kafka.clients.producer.Callback;
 import org.apache.kafka.clients.producer.RecordMetadata;
@@ -41,6 +30,17 @@ import org.kaaproject.kaa.server.common.log.shared.avro.gen.RecordHeader;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+
 public class KafkaLogAppender extends AbstractLogAppender<KafkaConfig> {
 
     private static final Logger LOG = LoggerFactory.getLogger(KafkaLogAppender.class);
@@ -111,20 +111,24 @@ public class KafkaLogAppender extends AbstractLogAppender<KafkaConfig> {
                                 .getSchema());
                         GenericAvroConverter<GenericRecord> headerConverter = getConverter(header.getSchema()
                                 .toString());
+
+                        String clientProfile = logEventPack.getClientProfile().getBody();
+                        String serverProfile = logEventPack.getServerProfile().getBody();
+
                         List<KafkaLogEventDto> dtoList = generateKafkaLogEvent(logEventPack, header, eventConverter);
                         LOG.debug("[{}] saving {} objects", topicName, dtoList.size());
                         if (!dtoList.isEmpty()) {
                             int logCount = dtoList.size();
                             inputLogCount.getAndAdd(logCount);
-                            logEventDao.save(dtoList, eventConverter, headerConverter, new LogAppenderCallback(
+                            logEventDao.save(dtoList, eventConverter, headerConverter, clientProfile, serverProfile, new LogAppenderCallback(
                                     listener, kafkaSuccessLogCount, kafkaFailureLogCount));
                             LOG.debug("[{}] appended {} logs to kafka collection", topicName, logEventPack.getEvents()
                                     .size());
                         } else {
                             listener.onInternalError();
                         }
-                    } catch (Exception e) {
-                        LOG.warn("Got exception. Can't process log events", e);
+                    } catch (Exception ex) {
+                        LOG.warn("Got exception. Can't process log events", ex);
                         listener.onInternalError();
                     }
                 }
@@ -152,7 +156,7 @@ public class KafkaLogAppender extends AbstractLogAppender<KafkaConfig> {
     }
 
     protected List<KafkaLogEventDto> generateKafkaLogEvent(LogEventPack logEventPack, RecordHeader header,
-            GenericAvroConverter<GenericRecord> eventConverter) throws IOException {
+                                                           GenericAvroConverter<GenericRecord> eventConverter) throws IOException {
         LOG.debug("Generate LogEventDto objects from LogEventPack [{}] and header [{}]", logEventPack, header);
         List<KafkaLogEventDto> events = new ArrayList<>(logEventPack.getEvents().size());
         try {
@@ -180,7 +184,7 @@ public class KafkaLogAppender extends AbstractLogAppender<KafkaConfig> {
         private final int size;
 
         private LogAppenderCallback(LogDeliveryCallback callback, AtomicInteger kafkaSuccessLogCount,
-                AtomicInteger kafkaFailureLogCount) {
+                                    AtomicInteger kafkaFailureLogCount) {
             this.callback = callback;
             this.kafkaSuccessLogCount = kafkaSuccessLogCount;
             this.kafkaFailureLogCount = kafkaFailureLogCount;
@@ -207,8 +211,7 @@ public class KafkaLogAppender extends AbstractLogAppender<KafkaConfig> {
     /**
      * Gets the converter.
      *
-     * @param schema
-     *            the schema
+     * @param schema the schema
      * @return the converter
      */
     private GenericAvroConverter<GenericRecord> getConverter(String schema) {
diff --git a/server/appenders/kafka-appender/src/main/java/org/kaaproject/kaa/server/appenders/kafka/appender/KafkaLogEventDao.java b/server/appenders/kafka-appender/src/main/java/org/kaaproject/kaa/server/appenders/kafka/appender/KafkaLogEventDao.java
index ee93c78..28e7512 100644
--- a/server/appenders/kafka-appender/src/main/java/org/kaaproject/kaa/server/appenders/kafka/appender/KafkaLogEventDao.java
+++ b/server/appenders/kafka-appender/src/main/java/org/kaaproject/kaa/server/appenders/kafka/appender/KafkaLogEventDao.java
@@ -16,14 +16,6 @@
 
 package org.kaaproject.kaa.server.appenders.kafka.appender;
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Properties;
-import java.util.Random;
-import java.util.UUID;
-import java.util.concurrent.Future;
-
 import org.apache.avro.generic.GenericRecord;
 import org.apache.kafka.clients.producer.Callback;
 import org.apache.kafka.clients.producer.KafkaProducer;
@@ -36,6 +28,14 @@ import org.kaaproject.kaa.server.appenders.kafka.config.gen.KafkaServer;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Properties;
+import java.util.Random;
+import java.util.UUID;
+import java.util.concurrent.Future;
+
 public class KafkaLogEventDao implements LogEventDao {
 
     private static final Logger LOG = LoggerFactory.getLogger(KafkaLogEventDao.class);
@@ -89,19 +89,19 @@ public class KafkaLogEventDao implements LogEventDao {
 
     @Override
     public List<Future<RecordMetadata>> save(List<KafkaLogEventDto> logEventDtoList,
-            GenericAvroConverter<GenericRecord> eventConverter, GenericAvroConverter<GenericRecord> headerConverter,
-            Callback callback) throws IOException {
+                                             GenericAvroConverter<GenericRecord> eventConverter, GenericAvroConverter<GenericRecord> headerConverter,
+                                             String clientProfile, String serverProfile, Callback callback) throws IOException {
         List<Future<RecordMetadata>> results = new ArrayList<Future<RecordMetadata>>();
         LOG.info("[{}] Sending events to Kafka using {} key defining strategy", topicName, configuration
                 .getKafkaKeyType().toString());
         for (KafkaLogEventDto dto : logEventDtoList) {
             ProducerRecord<String, String> recordToWrite;
             if (configuration.getUseDefaultPartitioner()) {
-                recordToWrite = new ProducerRecord<String, String>(topicName, getKey(dto), formKafkaJSON(dto,
-                        eventConverter, headerConverter));
+                recordToWrite = new ProducerRecord<String, String>(topicName, getKey(dto), formKafkaJson(dto,
+                        eventConverter, headerConverter, clientProfile, serverProfile));
             } else {
                 recordToWrite = new ProducerRecord<String, String>(topicName, calculatePartitionID(dto), getKey(dto),
-                        formKafkaJSON(dto, eventConverter, headerConverter));
+                        formKafkaJson(dto, eventConverter, headerConverter, clientProfile, serverProfile));
             }
             results.add(producer.send(recordToWrite, callback));
         }
@@ -122,41 +122,44 @@ public class KafkaLogEventDao implements LogEventDao {
 
     private String parseAcknowledgement(String record) {
         switch (record) {
-        case "ALL":
-            return "all";
-        case "ZERO":
-            return "0";
-        case "ONE":
-            return "1";
-        case "TWO":
-            return "2";
-        default:
-            return "";
+            case "ALL":
+                return "all";
+            case "ZERO":
+                return "0";
+            case "ONE":
+                return "1";
+            case "TWO":
+                return "2";
+            default:
+                return "";
         }
     }
 
-    private String formKafkaJSON(KafkaLogEventDto dto, GenericAvroConverter<GenericRecord> eventConverter,
-            GenericAvroConverter<GenericRecord> headerConverter) throws IOException {
-        String eventJSON = eventConverter.encodeToJson(dto.getEvent());
-        String headerJSON = headerConverter.encodeToJson(dto.getHeader());
+    private String formKafkaJson(KafkaLogEventDto dto, GenericAvroConverter<GenericRecord> eventConverter,
+                                 GenericAvroConverter<GenericRecord> headerConverter,
+                                 String clientProfile, String serverProfile) throws IOException {
+        String eventJson = eventConverter.encodeToJson(dto.getEvent());
+        String headerJson = headerConverter.encodeToJson(dto.getHeader());
         StringBuilder result = new StringBuilder("{");
-        if (headerJSON != null && !headerJSON.isEmpty()) {
-            result.append("\"header\":" + headerJSON + ",");
+        if (headerJson != null && !headerJson.isEmpty()) {
+            result.append("\"header\":" + headerJson + ",");
         }
-        result.append("\"event\":" + eventJSON + "}");
+        result.append("\"event\":" + eventJson + ",");
+        result.append("\"clientProfile\":" + clientProfile + ",");
+        result.append("\"serverProfile\":" + serverProfile + "}");
         return result.toString();
     }
 
     private String getKey(KafkaLogEventDto dto) {
         switch (configuration.getKafkaKeyType()) {
-        case ENDPOINTHASHKEY:
-            return dto.getHeader().getEndpointKeyHash();
-        case UUID:
-            return new UUID(System.currentTimeMillis(), RANDOM.nextLong()).toString();
-        case HASH:
-            return "" + dto.hashCode();
-        default:
-            return null;
+            case ENDPOINTHASHKEY:
+                return dto.getHeader().getEndpointKeyHash();
+            case UUID:
+                return new UUID(System.currentTimeMillis(), RANDOM.nextLong()).toString();
+            case HASH:
+                return "" + dto.hashCode();
+            default:
+                return null;
         }
     }
 }
diff --git a/server/appenders/kafka-appender/src/main/java/org/kaaproject/kaa/server/appenders/kafka/appender/LogEventDao.java b/server/appenders/kafka-appender/src/main/java/org/kaaproject/kaa/server/appenders/kafka/appender/LogEventDao.java
index 36a4de5..b2a4d66 100644
--- a/server/appenders/kafka-appender/src/main/java/org/kaaproject/kaa/server/appenders/kafka/appender/LogEventDao.java
+++ b/server/appenders/kafka-appender/src/main/java/org/kaaproject/kaa/server/appenders/kafka/appender/LogEventDao.java
@@ -16,20 +16,21 @@
 
 package org.kaaproject.kaa.server.appenders.kafka.appender;
 
-import java.io.IOException;
-import java.util.List;
-import java.util.concurrent.Future;
-
 import org.apache.avro.generic.GenericRecord;
 import org.apache.kafka.clients.producer.Callback;
 import org.apache.kafka.clients.producer.RecordMetadata;
 import org.kaaproject.kaa.common.avro.GenericAvroConverter;
 
+import java.io.IOException;
+import java.util.List;
+import java.util.concurrent.Future;
+
 public interface LogEventDao {
 
     List<Future<RecordMetadata>> save(List<KafkaLogEventDto> logEventDtoList,
-            GenericAvroConverter<GenericRecord> eventConverter, GenericAvroConverter<GenericRecord> headerConverter,
-            Callback callback) throws IOException;
+                                      GenericAvroConverter<GenericRecord> eventConverter, GenericAvroConverter<GenericRecord> headerConverter,
+                                      String clientProfile, String serverProfile,
+                                      Callback callback) throws IOException;
 
     void close();
 }
\ No newline at end of file
-- 
2.9.3

